{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "58423fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tritonclient.grpc as grpcclient\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import heapq\n",
    "import time\n",
    "from bert_python.bert import Config\n",
    "triton_client = grpcclient.InferenceServerClient(url=\"10.113.4.193:8021\")\n",
    "\n",
    "config = Config(\"bert_model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7e97b416",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['我', '想', '买', '一', '辆', '自', '行', '车']\n"
     ]
    }
   ],
   "source": [
    "text = '我想买一辆自行车'\n",
    "print(config.tokenizer.tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9843f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id2name():\n",
    "    with open(\"bert_model/query/catid3_and_catname3\",encoding=\"utf-8\") as f:\n",
    "        cat = {}\n",
    "        for line in f.readlines():\n",
    "            cat[line.split()[0]] = line.split()[1]\n",
    "    return cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ae2e8d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer \n",
    "def fine_grade_tokenize(text):\n",
    "    PAD, CLS = '[PAD]', '[CLS]'\n",
    "    PAD_SIZE = config.pad_size\n",
    "    token = config.tokenizer.tokenize(text)\n",
    "    token = [CLS] + token\n",
    "    tokens = config.tokenizer.convert_tokens_to_ids(token)\n",
    "    seq_len = len(token)\n",
    "\n",
    "    if len(token) < PAD_SIZE:\n",
    "        mask = [1] * len(tokens) + [0] * (PAD_SIZE - len(token))\n",
    "        tokens += ([0] * (PAD_SIZE - len(token)))\n",
    "    else:\n",
    "        mask = [1] * PAD_SIZE\n",
    "        tokens = tokens[:PAD_SIZE]\n",
    "    return (tokens, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "64adfaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess for text input\n",
    "def preprocess(text):\n",
    "    tokens, mask = fine_grade_tokenize(text)\n",
    "    input_feed = {'input_ids': [tokens],\n",
    "                  'attention_mask': [mask] }\n",
    "    input_ids = np.array(input_feed['input_ids'], dtype=np.int64)\n",
    "    attention_mask = np.array(input_feed['attention_mask'],dtype=np.int64)\n",
    "\n",
    "    return (input_ids,attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3c3a4177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# postprocess\n",
    "def post_process(output):\n",
    "    label = F.softmax(torch.LongTensor(output)/2,1).cpu()\n",
    "    tmp = zip(range(len(label.data[0])),label.data[0].numpy())\n",
    "    max_five = heapq.nlargest(5,tmp,key=lambda x:x[1])\n",
    "    cat = id2name()\n",
    "    for i in max_five:\n",
    "        print(cat[config.class_list[i[0]]],i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fde9751d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.0537105  -2.006245   -3.3541844  ... -0.14689699 -0.6333689\n",
      "   0.49530295]]\n",
      "自行车 0.19553654\n",
      "自行车整车 0.07193387\n",
      "雨伞雨具 0.00973519\n",
      "体感车 0.00973519\n",
      "学步车/三轮车 0.00973519\n",
      "None\n",
      "推理时间： 0.003985404968261719\n"
     ]
    }
   ],
   "source": [
    "# test for bert_classifier \n",
    "\n",
    "text = '我想买一辆自行车'\n",
    "model_version = '1'\n",
    "model_name = 'bert_classify'\n",
    "input_ids,attention_mask = preprocess(text)\n",
    "nb_tokens = config.pad_size\n",
    "input0 = grpcclient.InferInput('input_ids',(1,nb_tokens), 'INT64')\n",
    "input0.set_data_from_numpy(input_ids)\n",
    "input1 = grpcclient.InferInput('attention_mask',(1,nb_tokens), 'INT64')\n",
    "input1.set_data_from_numpy(attention_mask)\n",
    "output = grpcclient.InferRequestedOutput(\"output\")\n",
    "\n",
    "#推理\n",
    "s_t = time.time()\n",
    "response = triton_client.infer(model_name=model_name, model_version=model_version, inputs=[input0,input1], outputs=[output])\n",
    "s_e = time.time()\n",
    "output0_data = response.as_numpy(\"output\")\n",
    "\n",
    "print(post_process(output0_data))\n",
    "print(\"推理时间：\",s_e-s_t) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "88f4c605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"自行车\": \"0.1955\", \"自行车整车\": \"0.0719\", \"雨伞雨具\": \"0.0097\", \"体感车\": \"0.0097\", \"学步车/三轮车\": \"0.0097\"}\n",
      "推理时间： 0.014065265655517578\n"
     ]
    }
   ],
   "source": [
    "# demo 推理\n",
    "model_version = '1'\n",
    "model_name = 'flow'\n",
    "\n",
    "query = grpcclient.InferInput(name='INPUT',shape=(1,), datatype=\"BYTES\")\n",
    "query.set_data_from_numpy(np.asarray([text],dtype=object))\n",
    "output = grpcclient.InferRequestedOutput(name=\"OUTPUT\")\n",
    "\n",
    "s_t = time.time()\n",
    "response = triton_client.infer(model_name=model_name, model_version=model_version, inputs=[query], outputs=[output])\n",
    "s_e = time.time()\n",
    "\n",
    "output0_data = response.as_numpy(\"OUTPUT\")\n",
    "\n",
    "\n",
    "a = output0_data.reshape(-1,1)\n",
    "print(a[0][0].decode())\n",
    "print(\"推理时间：\",s_e-s_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bbe79d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推理时间： 53.93218016624451\n"
     ]
    }
   ],
   "source": [
    "# 10000次请求测试\n",
    "\n",
    "model_name = 'flow'\n",
    "model_version = '1'\n",
    "text = '我想买一辆自行车'\n",
    "\n",
    "query = grpcclient.InferInput(name='INPUT',shape=(1,), datatype=\"BYTES\")\n",
    "query.set_data_from_numpy(np.asarray([text], dtype=object))\n",
    "output = grpcclient.InferRequestedOutput(\"OUTPUT\")\n",
    "\n",
    "def perform_random_inference():\n",
    "    triton_client.infer(model_name,model_version=model_version, inputs=[query],outputs=[output])\n",
    "\n",
    "s_t = time.time()\n",
    "for _ in range(10000):\n",
    "    perform_random_inference()\n",
    "\n",
    "s_e = time.time()   \n",
    "print(\"推理时间：\",s_e-s_t) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4c012ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[b'{\"\\xe8\\x87\\xaa\\xe8\\xa1\\x8c\\xe8\\xbd\\xa6\": \"0.1350\", \"\\xe8\\x87\\xaa\\xe8\\xa1\\x8c\\xe8\\xbd\\xa6\\xe6\\x95\\xb4\\xe8\\xbd\\xa6\": \"0.0497\", \"\\xe9\\x9b\\xa8\\xe4\\xbc\\x9e\\xe9\\x9b\\xa8\\xe5\\x85\\xb7\": \"0.0111\", \"\\xe4\\xbd\\x93\\xe6\\x84\\x9f\\xe8\\xbd\\xa6\": \"0.0111\", \"\\xe5\\xad\\xa6\\xe6\\xad\\xa5\\xe8\\xbd\\xa6/\\xe4\\xb8\\x89\\xe8\\xbd\\xae\\xe8\\xbd\\xa6\": \"0.0111\"}']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"自行车\": \"0.1350\", \"自行车整车\": \"0.0497\", \"雨伞雨具\": \"0.0111\", \"体感车\": \"0.0111\", \"学步车/三轮车\": \"0.0111\"}'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output0_data = response.as_numpy(\"OUTPUT\")\n",
    "# output0_data[0]\n",
    "print(output0_data.reshape(-1,1))\n",
    "a = output0_data.reshape(-1,1)\n",
    "a[0][0].decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a068cbd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'NoneType'>\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-111-ac1a1176d2b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput0_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# print(np.asarray(output0_data))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput0_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# np.set_printoptions(threshold=10_000)\n",
    "print(type(output0_data))\n",
    "# print(np.asarray(output0_data))\n",
    "print(output0_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "980420da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101, 2769, 2682, 743, 671, 6775, 5632, 6121, 6756, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "input_feed ={'input_ids': [[101,\n",
    "   2769,\n",
    "   2682,\n",
    "   743,\n",
    "   671,\n",
    "   6775,\n",
    "   5632,\n",
    "   6121,\n",
    "   6756,\n",
    "   0,\n",
    "   0,\n",
    "   0,\n",
    "   0,\n",
    "   0,\n",
    "   0]],\n",
    " 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]]}\n",
    "\n",
    "print(input_feed['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3b16c2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(input_feed['attention_mask'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2f33b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "\n",
    "# np.array([\"IOS\"], dtype=np.object_)\n",
    "# in0n = np.array([\"我勒个老天啊\"], dtype=np.object_)\n",
    "# input0_data = in0n.reshape((-1, 1))\n",
    "nb_tokens = 15\n",
    "\n",
    "input_ids = np.array(input_feed['input_ids'], dtype=np.int64)\n",
    "\n",
    "attention_mask = np.array(input_feed['attention_mask'],dtype=np.int64)\n",
    "\n",
    "input0 = grpcclient.InferInput('input_ids',(1,nb_tokens), 'INT64')\n",
    "input0.set_data_from_numpy(input_ids)\n",
    "input1 = grpcclient.InferInput('attention_mask',(1,nb_tokens), 'INT64')\n",
    "input1.set_data_from_numpy(attention_mask)\n",
    "\n",
    "output = grpcclient.InferRequestedOutput(\"output\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92fe1e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推理时间： 0.007288455963134766\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "model_version = '1'\n",
    "model_name = 'bert_classify'\n",
    "s_t = time.time()\n",
    "response = triton_client.infer(model_name=model_name, model_version=model_version, inputs=[input0,input1], outputs=[output])\n",
    "s_e = time.time()\n",
    "output0_data = response.as_numpy(\"output\")\n",
    "print(\"推理时间：\",s_e-s_t) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3253114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自行车 0.19553654\n",
      "自行车整车 0.07193387\n",
      "雨伞雨具 0.00973519\n",
      "体感车 0.00973519\n",
      "学步车/三轮车 0.00973519\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(post_process(output0_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d6623734",
   "metadata": {},
   "outputs": [
    {
     "ename": "InferenceServerException",
     "evalue": "[StatusCode.UNAVAILABLE] Request for unknown model: 'bert_classify' is not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInferenceServerException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-136-913b8dbf2915>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0ms_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mperform_random_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0ms_e\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-136-913b8dbf2915>\u001b[0m in \u001b[0;36mperform_random_inference\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mperform_random_inference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0minput0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data_from_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mtriton_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0ms_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/anaconda3/lib/python3.8/site-packages/tritonclient/grpc/__init__.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, model_name, inputs, model_version, outputs, request_id, sequence_id, sequence_start, sequence_end, priority, timeout, client_timeout, headers, compression_algorithm)\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrpc_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1156\u001b[0;31m             \u001b[0mraise_error_grpc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrpc_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m     def async_infer(self,\n",
      "\u001b[0;32m/app/anaconda3/lib/python3.8/site-packages/tritonclient/grpc/__init__.py\u001b[0m in \u001b[0;36mraise_error_grpc\u001b[0;34m(rpc_error)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_error_grpc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrpc_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mget_error_grpc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrpc_error\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInferenceServerException\u001b[0m: [StatusCode.UNAVAILABLE] Request for unknown model: 'bert_classify' is not found"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import time\n",
    "model_name = 'bert_classify'\n",
    "model_version = '1'\n",
    "nb_tokens = 15\n",
    "\n",
    "input0 = grpcclient.InferInput('input_ids',(1,nb_tokens), 'INT64')\n",
    "input1 = grpcclient.InferInput('attention_mask',(1,nb_tokens), 'INT64')\n",
    "input1.set_data_from_numpy(np.ones((1,nb_tokens), dtype=np.int64))\n",
    "\n",
    "\n",
    "output = grpcclient.InferRequestedOutput(\"output\")\n",
    "\n",
    "def perform_random_inference():\n",
    "    input0.set_data_from_numpy(np.random.randint(10000,size=(1, nb_tokens),dtype=np.int64))\n",
    "    triton_client.infer(model_name,model_version=model_version, inputs=[input0,input1],outputs=[output])\n",
    "\n",
    "s_t = time.time()\n",
    "for _ in range(10000):\n",
    "    perform_random_inference()\n",
    "\n",
    "s_e = time.time()   \n",
    "print(\"推理时间：\",s_e-s_t) \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda72ff8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4304f1bb",
   "metadata": {},
   "source": [
    "## HTTP client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "22f25e57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推理时间： 29.44158172607422\n"
     ]
    }
   ],
   "source": [
    "import tritonclient.http\n",
    "import numpy as np\n",
    "triton_client_http = tritonclient.http.InferenceServerClient(url=\"10.113.4.193:8020\")\n",
    "input0 = tritonclient.http.InferInput('input_ids',(1,nb_tokens), 'INT64')\n",
    "input1 = tritonclient.http.InferInput('attention_mask',(1,nb_tokens), 'INT64')\n",
    "input1.set_data_from_numpy(np.ones((1,nb_tokens), dtype=np.int64))\n",
    "\n",
    "output = tritonclient.http.InferRequestedOutput(\"output\")\n",
    "\n",
    "def perform_random_inference_http():\n",
    "    input0.set_data_from_numpy(np.random.randint(10000,size=(1, nb_tokens),dtype=np.int64))\n",
    "    triton_client_http.infer(model_name, \n",
    "                             model_version=model_version, \n",
    "                             inputs=[input0,input1],\n",
    "                             outputs=[output])\n",
    "\n",
    "s_t = time.time()\n",
    "for _ in range(10000):\n",
    "    perform_random_inference_http()\n",
    "\n",
    "s_e = time.time()   \n",
    "print(\"推理时间：\",s_e-s_t) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c3525560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import triton_python_backend_utils as pb_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbea146",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class tritonPythonModel:\n",
    "    def initialize(self, _):\n",
    "        self.tokenizer = \n",
    "        \n",
    "    def execute(self, requests):\n",
    "        responses = []\n",
    "        for request in requests:\n",
    "            query = [t.decode('UTF-8') for t in pb_utils.get_input_tensor_by_name(request,'TEXT').as_numpy().tolist()]\n",
    "            tokens = self.tokenizer(text=query)\n",
    "            input_ids = pb_utils.Tensor(\"input_ids\", tokens['input_ids'])\n",
    "            attention_mask = pb_utils.Tensor(\"attention_mask\", tokens['attention_mask'])\n",
    "            inference_response = pb_utils.InfereneResponse(output_tensors=[input_ids, attention_mask])\n",
    "            responses.append(inference_response)\n",
    "            \n",
    "            \n",
    "        return repsonses     \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240f780e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import base64\n",
    "\n",
    "url = 'http://127.0.0.1:18080/predictions/objDetect'\n",
    "img_path = 'test.jpeg'\n",
    "with open(img_path,\"rb\") as f:#转为二进制格式\n",
    "    base64_data = base64.b64encode(f.read())#使用base64进行编码\n",
    "base64_data = base64_data.decode()\n",
    "req_data = {\n",
    "    \"imgData\":base64_data\n",
    "}\n",
    "r = requests.post(url=url, data=json.dumps(req_data))\n",
    "print(json.loads(r.text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
