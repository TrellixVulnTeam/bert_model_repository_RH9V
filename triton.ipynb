{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import heapq\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "from bert_python.bert import Model, Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): Model(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): BertLayerNorm()\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): BertLayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): BertLayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): BertLayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): BertLayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): BertLayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): BertLayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): BertLayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): BertLayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): BertLayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): BertLayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): BertLayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): BertLayerNorm()\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (fc): Linear(in_features=768, out_features=1297, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') \n",
    "config = Config(\"bert_model/\")\n",
    "model = Model(config)\n",
    "model=nn.DataParallel(model,device_ids=[0])\n",
    "model.load_state_dict(torch.load(config.save_path, map_location=device))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mappping id to names\n",
    "def id2name():\n",
    "    with open(\"bert_model/query/catid3_and_catname3\",encoding=\"utf-8\") as f:\n",
    "        cat = {}\n",
    "        for line in f.readlines():\n",
    "            cat[line.split()[0]] = line.split()[1]\n",
    "    return cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer\n",
    "def fine_grade_tokenize(text):\n",
    "    PAD, CLS = '[PAD]', '[CLS]'\n",
    "    PAD_SIZE = 15\n",
    "    token = config.tokenizer.tokenize(text)\n",
    "    token = [CLS] + token\n",
    "    tokens = config.tokenizer.convert_tokens_to_ids(token)\n",
    "    seq_len = len(token)\n",
    "\n",
    "    if len(token) < PAD_SIZE:\n",
    "        mask = [1] * seq_len + [0] * (PAD_SIZE - seq_len)\n",
    "        tokens += ([0] * (PAD_SIZE - seq_len))\n",
    "    else:\n",
    "        mask = [1] * PAD_SIZE\n",
    "        tokens = tokens[:PAD_SIZE]\n",
    "    return (tokens, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess for text input\n",
    "def preprocess(text):\n",
    "    tokens, mask = fine_grade_tokenize(text)\n",
    "    input_feed = {'input_ids': [tokens],\n",
    "                  'attention_mask': [mask] }\n",
    "    input_ids = np.array(input_feed['input_ids'], dtype=np.int64)\n",
    "    attention_mask = np.array(input_feed['attention_mask'],dtype=np.int64)\n",
    "\n",
    "    return (input_ids,attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# postprocess\n",
    "def post_process(output):\n",
    "    label = F.softmax(torch.LongTensor(output)/2,1).cpu()\n",
    "    tmp = zip(range(len(label.data[0])),label.data[0].numpy())\n",
    "    max_five = heapq.nlargest(5,tmp,key=lambda x:x[1])\n",
    "    cat = id2name()\n",
    "    for i in max_five:\n",
    "        print(cat[config.class_list[i[0]]],i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自行车 0.19591652\n",
      "自行车整车 0.0791495\n",
      "体感车 0.0136031285\n",
      "学步车/三轮车 0.011366833\n",
      "雨伞雨具 0.009692598\n",
      "推理时间： 0.01837778091430664\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "text = '我想买一辆自行车'\n",
    "    \n",
    "with torch.no_grad():\n",
    "    #前处理\n",
    "    tokens, mask = fine_grade_tokenize(text)\n",
    "    input_ids = torch.LongTensor([tokens]).to(device)\n",
    "    attention_mask = torch.LongTensor([mask]).to(device)\n",
    "    s_t = time.time() \n",
    "    label = model(input_ids, attention_mask)\n",
    "    s_e = time.time()\n",
    "    #后处理\n",
    "    label = F.softmax(label/2,1).cpu()\n",
    "    tmp = zip(range(len(label.data[0])),label.data[0].numpy())\n",
    "    max_five = heapq.nlargest(5,tmp,key=lambda x:x[1])\n",
    "    cat = id2name()\n",
    "    for i in max_five:\n",
    "        print(cat[config.class_list[i[0]]],i[1])\n",
    "\n",
    "    print(\"推理时间：\",s_e-s_t) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert torch model to onnx\n",
    "# opset_version = 12\n",
    "# onnx_model_path = './onnx/text_classification_test.onnx'\n",
    "# if isinstance(model, torch.nn.DataParallel):\n",
    "#     model = model.module\n",
    "\n",
    "# inputs = {\n",
    "#     'input_ids': input_ids,\n",
    "#     'attention_mask':attention_mask\n",
    "# }    \n",
    "    \n",
    "# with torch.no_grad():\n",
    "#     torch.onnx.export(\n",
    "#         model,\n",
    "#         tuple(inputs.values()),\n",
    "#         onnx_model_path,\n",
    "#         opset_version=opset_version,\n",
    "#         input_names=['input_ids','attention_mask'],\n",
    "#         output_names=['output'],\n",
    "#         dynamic_axes={\n",
    "#             'input_ids': {0: 'batch_size', 1: 'sequence_len'},\n",
    "#             'attention_mask':{0: 'batch_size', 1: 'sequence_len'},\n",
    "#             'output': {0: 'batch_size'},\n",
    "#         }\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Quantization\n",
    "# from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "# import os\n",
    "# quantized_onnx_model_path = './onnx/quantized_text_classification.onnx'\n",
    "# quantize_dynamic(\n",
    "#     onnx_model_path,\n",
    "#     quantized_onnx_model_path,\n",
    "#     weight_type=QuantType.QUInt8\n",
    "# )\n",
    "# print('ONNX full precision model size (MB):', os.path.getsize(onnx_model_path) / (1024 * 1024))\n",
    "# print('ONNX quantized model size (MB):', os.path.getsize(quantized_onnx_model_path) / (1024 * 1024))\n",
    "\n",
    "\n",
    "# ```\n",
    "# #ONNX full precision model size (MB): 393.99146270751953\n",
    "# #ONNX quantized model size (MB): 98.92753601074219\n",
    "# ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## onnx test on gpu\n",
    "import onnx\n",
    "import onnxruntime\n",
    "assert 'CUDAExecutionProvider' in onnxruntime.get_available_providers()\n",
    "import psutil\n",
    "from onnxruntime import InferenceSession, SessionOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inference_session_gpu(\n",
    "    model_path: str,\n",
    "    provider: str = 'CUDAExecutionProvider'\n",
    ") -> InferenceSession: \n",
    "\n",
    "    options = SessionOptions()\n",
    "    options.intra_op_num_threads = psutil.cpu_count(logical=True)\n",
    "\n",
    "    # load the model as a onnx graph\n",
    "    session = InferenceSession(model_path, options,providers=[provider])\n",
    "    session.disable_fallback()\n",
    "    return session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自行车 0.19553654\n",
      "自行车整车 0.07193387\n",
      "雨伞雨具 0.00973519\n",
      "体感车 0.00973519\n",
      "学步车/三轮车 0.00973519\n",
      "推理时间： 0.004433631896972656\n"
     ]
    }
   ],
   "source": [
    "onnx_model_path = './onnx/text_classification_test.onnx'\n",
    "session_gpu = create_inference_session_gpu(onnx_model_path)\n",
    "tokens, mask = fine_grade_tokenize(text)\n",
    "input_feed = {'input_ids': [tokens],\n",
    "              'attention_mask': [mask] }\n",
    "s_t = time.time()\n",
    "onnx_output_gpu = session_gpu.run(['output'], input_feed)[0]\n",
    "s_e = time.time()\n",
    "# 后处理\n",
    "post_process(onnx_output_gpu)\n",
    "\n",
    "print(\"推理时间：\",s_e-s_t) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # optimized model\n",
    "# from onnxruntime.transformers import optimizer\n",
    "\n",
    "# optimized_fp16_model_path = './onnx/op_text_classification_fp16.onnx'\n",
    "# !{sys.executable} -m onnxruntime.transformers.optimizer --input $onnx_model_path --output $optimized_fp16_model_path --float16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "自行车 0.19549665\n",
      "自行车整车 0.0719192\n",
      "雨伞雨具 0.009733205\n",
      "体感车 0.009733205\n",
      "学步车/三轮车 0.009733205\n",
      "推理时间： 0.0036292076110839844\n"
     ]
    }
   ],
   "source": [
    "# optimized_onnx on gpu fp16\n",
    "optimized_fp16_model_path = './onnx/op_text_classification_fp16.onnx'\n",
    "op_session_fp16 = create_inference_session_gpu(optimized_fp16_model_path)\n",
    "s_t = time.time()\n",
    "op_onnx_output_fp16 = op_session_fp16.run(['output'], input_feed)[0]\n",
    "s_e = time.time()\n",
    "post_process(op_onnx_output_fp16)\n",
    "print(\"推理时间：\",s_e-s_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tritonclient.grpc as grpcclient\n",
    "triton_client = grpcclient.InferenceServerClient(url=\"l27.0.0.1:8021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"自行车\": \"0.1955\", \"自行车整车\": \"0.0719\", \"雨伞雨具\": \"0.0097\", \"体感车\": \"0.0097\", \"学步车/三轮车\": \"0.0097\"}\n",
      "推理时间： 0.014091730117797852\n"
     ]
    }
   ],
   "source": [
    "# demo 推理\n",
    "model_version = '1'\n",
    "model_name = 'flow'\n",
    "\n",
    "query = grpcclient.InferInput(name='INPUT',shape=(1,), datatype=\"BYTES\")\n",
    "query.set_data_from_numpy(np.asarray([text],dtype=object))\n",
    "output = grpcclient.InferRequestedOutput(name=\"OUTPUT\")\n",
    "\n",
    "s_t = time.time()\n",
    "response = triton_client.infer(model_name=model_name, model_version=model_version, inputs=[query], outputs=[output])\n",
    "s_e = time.time()\n",
    "\n",
    "output0_data = response.as_numpy(\"OUTPUT\")\n",
    "\n",
    "\n",
    "a = output0_data.reshape(-1,1)\n",
    "print(a[0][0].decode())\n",
    "print(\"推理时间：\",s_e-s_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test for bert_classifier\n",
    "# model_name = 'bert_classifier'\n",
    "# nb_tokens = config.pad_size\n",
    "# input0 = grpcclient.InferInput('input_ids',(1,nb_tokens), 'INT64')\n",
    "# input0.set_data_from_numpy(input_ids)\n",
    "# input1 = grpcclient.InferInput('attention_mask',(1,nb_tokens), 'INT64')\n",
    "# input1.set_data_from_numpy(attention_mask)\n",
    "# output = grpcclient.InferRequestedOutput(\"output\")\n",
    "\n",
    "# #推理\n",
    "# s_t = time.time()\n",
    "# response = triton_client.infer(model_name=model_name, model_version=model_version, inputs=[input0,input1], outputs=[output])\n",
    "# s_e = time.time()\n",
    "# output0_data = response.as_numpy(\"output\")\n",
    "\n",
    "# print(post_process(output0_data))\n",
    "# print(\"推理时间：\",s_e-s_t) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 10000次请求测试\n",
    "# query = grpcclient.InferInput(name='INPUT',shape=(1,), datatype=\"BYTES\")\n",
    "# query.set_data_from_numpy(np.asarray([text], dtype=object))\n",
    "# output = grpcclient.InferRequestedOutput(\"OUTPUT\")\n",
    "\n",
    "# def perform_random_inference():\n",
    "#     triton_client.infer(model_name,model_version=model_version, inputs=[query],outputs=[output])\n",
    "\n",
    "# s_t = time.time()\n",
    "# for _ in range(10000):\n",
    "#     perform_random_inference()\n",
    "# s_e = time.time()   \n",
    "# print(\"推理时间：\",s_e-s_t) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
